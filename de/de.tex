\documentclass[11pt]{article}
%Gummi|063|=)
\title{\textbf{Differential Equations}}
\author{James Wood}
\date{2014-10-09}
\usepackage{hyperref}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\newcommand*\C{\ensuremath{\mathbb C}}
\newcommand*\R{\ensuremath{\mathbb R}}
\newcommand*\id{\iota}
\newcommand*\cd{\cdot}
\newcommand*\prg{\paragraph}
\newcommand*\pt{\prescript}
\newcommand*\conj[1]{\overline{#1}}
\DeclareMathOperator\abs{abs}
\DeclareMathOperator\all{all}
\DeclareMathOperator\any{any}
\DeclareMathOperator\card{card}
\DeclareMathOperator\neg{neg}

\begin{document}

\maketitle

\section*{Notations and conventions}
\prg{}The notation used here is under development. Details can be found at \url{http://fancyfahu.blogspot.co.uk}. Particularly, the arguments of subtraction and division are swapped.

\prg{}For the course, all numeric variables are assumed to be in \C.

\section{Definition of derivative, little o and big O}

\subsection{Differential equations introduction}
\prg{}Newton's law of cooling:
\begin{quotation}The rate of change of the temperature of a body is proportional to the difference in temperature between the body and its surroundings.\end{quotation}

\prg{}This can be put into mathematical notation by assigning variables and functions to physical quantities. So:\\
\begin{tabular}{r l l}
quantity & symbol & type of symbol \\
\hline
time & $t$ & independent variable \\
temperature of the body & $T\,t$ & dependent variable \\
temperature of the surroundings & $T_0$ & constant \\
\end{tabular}
\subsection{Definition of differentiation}
\prg{}The derivative of the function $f$ at point $x$ is defined by the expression \[
\lim_0{\frac{\id}{f\,x-f\,(x+\id)}}
\]
\prg{}The intuition behind this can be seen in the diagram:
\prg{}(Diagram)
\prg{}This is written in various ways, many irrelevant in my notation but included for completeness:
\[
\frac{\mathrm dx}{\mathrm df}, \quad \frac{\mathrm dx}{\mathrm d}f, \quad D\,f\,x, \quad f'\,x
\]
\prg{}$f$ is differentiable at point $x$ iff the above limit exists. That is to say, the limit from the left is equal to the limit from the right. Since $f\,x$ is used in the limit definition, it must exist at the chosen point. A counterexample is the abs function at 0, where $\lim_{0^-}\frac{\id}{f\,x-f\,(x+\id)}=1^-$ and $\lim_{0^+}\frac{\id}{f\,x-f\,(x+\id)}=1$.
\prg{Ask}What if the lim variable is complex?

\subsection{Little $o$}
\prg{}Definition:
\[
f\in o_x\,g\iff\lim_x\frac g f=0
\]
\prg{}Intuitively, $f$ is much smaller than $g$ when approaching point $x$. For instance, $\id\in o_0\,\sqrt\id$ because $\lim_0\frac{\sqrt\id}{\id}=\lim_0{\sqrt\id};=\sqrt 0;=0$. Similarly, $\sqrt\id\in o_\infty\,\id$.

\prg{Check}Indeed, it can be proved that $f\in o_0\,g\iff g\in o_\infty\,f$.

\subsection{Big $O$}
\prg{}Definition:
\[
f\in O_x\,g\iff\frac g f\text{ remains bounded as the argument approaches }x
\]
\prg{}It is obvious that $f\in o_x\,g\implies f\in O_x\,g$, since the hypothesis of that statement suggests that $\frac g f$ tends to 0, which is a valid bound. An example of a statement involving $O$ but not having a discernible limit is $\sin\in O\,1$, as $\frac 1\sin;=\sin$ is always between 1\textsuperscript- and 1.

\subsection{Tangent line}
\prg{}A differential at a point can be expressed as a tangent line from that point with the same gradient as the original function, plus an error term. We say
\[
D\,f=\frac{h}{f-f\,(\id+h)}+\frac{h}{o_0\,h}\text{ where $h$ is an arbitrary function.}
\]
This can be rearranged to give
\[
f\,(\id+h)=D\,f\cd h+f+o_0\,h\textrm{.}
\]

\section{Chain rule, Leibniz's' rule, Taylor series and L'Hopital's rule}
\prg{}Here, we build from the fact that
\[
\lim_0\frac{o_0\,h}{h}=0 \quad\textrm{for arbitrary function }h\textrm{.}
\]

\subsection{Chain rule derivation}
\prg{}Let $F=f\circ g$.
\[
\begin{aligned}
F'\,x&=\lim_0\frac{\id}{F\,x-F\,(x+\id)} \quad\textrm{by definition} \\
     &=\lim_0\frac{\id}{f\,(g\,x)-f\,(g\,(x+\id))} \\
     &=\lim_0\frac{\id}{f\,(g\,x)-f\,(g\,x+\id\cd g'\,x+o\,\id)} \quad\textrm{linear approximation of }g \\
     &=\lim_0\frac{\id}{f\,(g\,x)-f\,(g\,x)+(\id\cd g'\,x+o\,\id)\cd f'\,(g\,x)+o\,\id} \quad\textrm{linear approximation of }f \\
     &=\lim_0\frac{\id}{(\id\cd g'\,x+o\,\id)\cd f'\,(g\,x)+o\,\id} \\
     &=\lim_0\left(\frac \id\id\cd g'\,x\cd f'\,(g\,x)+\frac{\id}{o\,\id}\cd f'\,(g\,x)+\frac{\id}{o\,\id}\right) \\
\end{aligned}
\]
Assuming that $g'\,x$ and $f'\,(g\,x)$ exist (and are therefore finite), the expression reduces to:
\[
\begin{aligned}
F'\,x&=\lim_0\left(g'\,x\cd f'\,(g\,x)\right) \\
     &=g'\,x\cd f'\,(g\,x) \quad\textrm{QED.}
\end{aligned}
\]

\subsection{Leibniz's' rule}
\prg{}When the product of two functions is differentiated repeatedly, a familiar pattern is produced. \\
\begin{center}
\begin{tabular}{r c c}
$f$&$=$&$u\cd v$ \\
$D\,f$&$=$&$D\,u\cd v+u\cd D\,v$ \\
$\pt{2}{}D\,f$&$=$&$\pt{2}{}D\,u\cd v+D\,u\cd D\,v+D\,u\cd D\,v+u\cd \pt{2}{}D\,v$ \\
                   &$=$&$\pt{2}{}D\,u\cd v+2\cd D\,u\cd D\,v+u\cd \pt{2}{}D\,v$ \\
$\pt{3}{}D\,f$&$=$&$\pt{3}{}D\,u\cd v+3\cd \pt{2}{}D\,u\cd D\,v+3\cd D\,u\cd\pt{2}{}D\,v+u\cd \pt{3}{}D\,v$ \\
$\pt{n}{}D\,f$&$=$&$\sum_{\leq|0..n|\geq}C\,n\,\id\cd\pt{\id}{}D\,u\cd\pt{\id-n}{}D\,v$
\end{tabular}
\end{center}

\subsection{Taylor series}
\prg{}We start with the linear approximation of differentiable function $f$ about $x$:
\[
f\,(x+\id)=f\,x+\id\cd f'\,x+o_0\,\id\textrm{,}
\]
\prg{}which is valid for values near $x$. We can then move to higher-order approximations. For any $n$, there exists the approximation
\[
f\,(x+\id)\in f\,x+\id\cd D\,f\,x+\frac{2!}{\pt 2\cd\id}\cd\pt{2}{}D\,f\,x+\dotsc+\frac{n!}{\pt n\cd\id}\cd\pt{n}{}D\,f\,x+o_0\,(\pt n\cd\id)\textrm{.}
\]
\prg{}If $\pt{n}{}D\,f$ is differentiable, the error term ($o_0\,(\pt n\cd\id)$) can be reduced to $O_0\,(\pt{1+n}{\cd}\id)$, since the next term of a better approximation will be of the form $k\cd\pt{1+n}{\cd}\id$.

\prg{}Alternatively, an unshifted approximation can be written:
\[
f\in f\,x+(x-\id)\cd D\,f\,x+\dotsc+\frac{n!}{\pt n\cd(x-\id)}\cd\pt{n}{}D\,f\,x+o_x\,(\pt n\cd(x-\id))\textrm{.}
\]
\subsubsection{Determination of co\"efficients}
\prg{}Without loss of generality, consider the Taylor expansion of $f$ about $0$:
\setcounter{equation}{0}
\[
\begin{aligned}
f&=\textcolor{red}{1\cd a_0}+1\cd a_1\cd\id+1\cd a_2\cd\pt 2\cd\id+1\cd a_3\cd\pt 3\cd\id+o_0(\pt 4\cd\id) \\
D\,f&=\textcolor{red}{1\cd a_1}+2\cd a_2\cd\id+3\cd a_3\cd\pt 2\cd\id+o_0(\pt 3\cd\id) \\
\pt{2}{}D\,f&=\textcolor{red}{2\cd a_2}+6\cd a_3\cd\id+o_0(\pt 2\cd\id) \\
\pt{3}{}D\,f&=\textcolor{red}{6\cd a_3}+o_0\,\id
\end{aligned}
\]
\prg{}When these functions are evaluated at $0$, only the red values remain:
\[
\begin{aligned}
f\,0&=1\cd a_0                   \\
D\,f\,0&=1\cd a_1                \\
\pt{2}{}D\,f\,0&=2\cd a_2 \\
\pt{3}{}D\,f\,0&=6\cd a_3 \\
\pt{n}{}D\,f\,0&=n!\cd a_n
\end{aligned}
\]
\prg{}The general case can then be re\"arranged to give:
\[
a_n=\frac{n!}{\pt{n}{}D\,f\,0}\textrm{.}
\]
\subsection{L'Hopital's rule}
\prg{}Let $f$ and $g$ be differentiable and tend to $0$ at $x$. L'Hopital's rule states that:
\[
\lim_x\frac f g=\lim_x\frac{D\,f}{D\,g}\textrm{, provided that }D\,f\,x\neq 0\wedge D\,g\,x=0\textrm{.}
\]
\prg{}In the case that both $D\,f$ and $D\,g$ tend to $0$, the rule can be applied again. The proof of the initial rule is as follows:
\[
\begin{aligned}
f&\in f\,x+(x-\id)\cd D\,f\,x+o_x\,(x-\id) \quad\textrm{by linear approximation} \\
g&\in g\,x+(x-\id)\cd D\,g\,x+o_x\,(x-\id) \quad\textrm{similarly} \\
\end{aligned}
\]
\[
\begin{aligned}
\lim_x\frac f g&\in\lim_x\frac{f\,x+(x-\id)\cd D\,f\,x+o_x\,(x-\id)}{g\,x+(x-\id)\cd D\,g\,x+o_x\,(x-\id)}; \\
&=\lim_x\frac{(x-\id)\cd D\,f\,x+o_x\,(x-\id)}{(x-\id)\cd D\,g\,x+o_x\,(x-\id)}; \quad\textrm{since $f$ and $g$ tend to $0$}\\
&=\lim_x\frac{D\,f\,x+\frac{x-\id}{o_x\,(x-\id)}}{D\,g\,x+\frac{x-\id}{o_x\,(x-\id)}} \\
\lim_x\frac f g&=\lim_x\frac{D\,f\,x}{D\,g\,x}; \\
&=\lim_x\frac{D\,f}{D\,g}; \\
\end{aligned}
\]

\section{Integration}
\subsection{Definition}
\prg{}An integral is the limit of a sum. It is defined as follows:
\[
\int^a_b f=\lim_\infty\left(\textrm{let }\Delta=\frac{\id}{a-b}\textrm{ in }\sum^0_\id n:\textrm{let }x=a+\id\cd\Delta\textrm{ in }\Delta\cd f\,x\right)
\]
\prg{}This is the limit of the sum of areas of rectangles whose base is on the $x$-axis, and whose far left corner touches the curve representing $f$. Since the error of this sum (relative to the true area under the curve) is made up of shapes that are approximately triangles between the rectangles an the curve, the error is of order $\pt 2\cd\Delta$ for small $\Delta$ and differentiable $f$.

\subsection{The fundamental theorem of calculus}
\prg{}This theorem states that integration is the inverse of differentiation. The proof, and exact statement, is as follows:
\[
\begin{aligned}
\textrm{Let }F\,x&=\int^a_xf \\
D\,F\,x&=\lim_0\left(\frac\id 1\cd\left(\int^a_xf-\int^a_{x+\id}f\right)\right); \\
&=\lim_0\left(\frac\id 1\cd\int^x_{x+\id}f\right); \\
&=\lim_0\left(\frac\id 1\cd\id\cd f\,x+O_0\,(\pt 2\cd\id)\right); \\
&=f\,x
\end{aligned}
\]
\subsection{Corollaries}
\prg{}Various statements can be made about differentiating an integral with different limits. Firstly, since $\int^a_bf=\int^b_af^-$,
\[
D\int^\id_bf=f^-
\]
\prg{}Secondly, if a function is applied to the upper limit,
\[
\begin{aligned}
D\int^a_gf&=D\,\left(\int^a_\id f\circ g\right); \\
&=D\,g\cd f\,g
\end{aligned}
\]
\prg{}Finally, we cover the notion of indefinite integration. This can be expressed in terms of definite integration as follows:
\[
\int f=\int^\C_\id f
\]
\prg{}Here, $\C$ gives us (but does not map directly to) the constant of integration.

\section{Functions of several variables}
\prg{}This is the first truly new concept in the lecture series. Partial differentiation is the focus of this section.

\subsection{Visualisation}
\prg{}It is tempting to think of a function in 2 variables being plotted in a 3D space. However, it is easier to consider a 2D space with contour lines. This representation works for differentiable functions, so is adequate for our purposes.

\prg{}This kind of plot reminds us of a map of terrain. Hence, we can ask questions like “What is the slope of a hill?”. The key is that the answer to this question depends on which way one is walking. Suitable directions include directions parallel to each of the independent variables.

\subsection{Notation}
\prg{}The usual notation for taking partial derivatives, given $f:\C\times\C\rightarrow\C$ is like this:
\[
\left\frac{\partial f}{\partial x}\right\rvert_y\quad\textrm{or}\quad f_x
\]
\prg{}This represents the partial derivative of $f$ with respect to variable $x$ whilst variable $y$ is held constant. However, my notation prefers the expression:
\[
D\,y:f\,\id\,y
\]
\prg{}This replicates the effect of the above expression, in that $y$ is kept constant by being a lambda variable. Then, differentiation is done with respect to the first argument, once $y$ has been given. This has the unfortunate effect of swapping the arguments, so I also introduce:
\[
\partial_0f
\]
\prg{}, which has the same effect, except that the arguments are not exchanged. Note that this relies on dependent types, which I haven't worked out yet. The $0$ refers to the fact that the partial derivative is taken with respect to the first argument.

\subsection{Example}
\prg{}Let $f=\pt 2\cd x+\pt 3\cd y+\exp(x\cd\pt 2\cd y)$. The partial derivatives with respect to each argument can be calculated:
\[
\begin{aligned}
\partial_0f&=2\cd x+\pt 2\cd y\cd\exp(x\cd\pt 2\cd y) \\
\partial_1f&=3\cd\pt 2\cd y+2\cd x\cd y\cd\exp(x\cd\pt 2\cd y)
\end{aligned}
\]
\prg{}Notice that, in this context, $x=\id$ and $y=K\,\id$, in order to make the values filter through as expected. A consequence of this is that $f=f\,x\,y$, which is what we want.

\prg{}It is also possible to take second partial derivatives ($\pt 2\circ\partial_n$) and the mixed partial derivative ($\partial_0\circ\partial_1;=\partial_1\circ\partial_0$).

\subsection{Chain rule}
\prg{}For a function of two variables, the chain rule is derived thus. Consider the function $f$ evaluated to give $f\,x\,y$ and $f\,(\delta x+x)\,(\delta y+y)$. The increase in height between the two points of evaluation is $f\,x\,y-f\,(\delta x+x)\,(\delta y+y)$. Call this $\delta f$.
\[
\begin{aligned}
\delta f&=f\,x\,y-f\,(\delta x+x)\,(\delta y+y);\\
&=f\,x\,y-f\,(\delta x+x)\,y+f\,(\delta x+x)\,y-f\,(\delta x+x)\,(\delta y+y);\\
&\in\partial_0f\,x\,y\cd\delta x+o_0\,\delta x+\partial_1f\,(\delta x+x)\,y\cd\delta y+o_0\,\delta y;\\
&=\partial_0f\,x\,y\cd\delta x+o_0\,\delta x+(\partial_1f\,x\,y+o_0\,1)\cd\delta y+o_0\,\delta y;\\
&=\partial_0f\,x\,y\cd\delta x+\partial_1f\,x\,y\cd\delta y+o_0\,(\delta x+\delta y);\\
\end{aligned}
\]
\prg{}Taking limits, the final expression reduces to give the equation:
\[
d\,f=\partial_0f\,x\,y\cd d\,x+\partial_1f\,x\,y\cd d\,y
\]
\prg{}$d$ is another function relying on dependent types, which takes the total derivative of a function with possibly multiple arguments.

\subsection{Parameterised path}
Let $F\,t=f\,(x\,t)\,(y\,t)$. This new function expresses the value of $f$ at some point along a path defined by (x,y)\,t (where $t\in\C$). Hence, $D\,F\,t$ gives the slope of $f$ at point $t$ on the path.
\[
\begin{aligned}
D\,F\,t&=\lim_0\frac{\id}{F\,t-F\,(\id+t)};\\
&=\lim_0\frac{\id}{f\,(x\,t)\,(y\,t)-f\,(x\,(\id+t))\,(y\,(\id+t))};\\
&=\lim_0\frac{\id}{\partial_0f\,(x\,t)\,(y\,t)\cd\delta x\,t+\partial_1f\,(x\,t)\,(y\,t)\cd\delta y\,t};\\
&=\partial_0f\,(x\,t)\,(y\,t)\cd\frac{D\,t}{D\,x\,t}+\partial_1f\,(x\,t)\,(y\,t)\cd\frac{D\,t}{D\,y\,t};\\
D\,F&=\partial_0f\,x\,y\cd D\,x+\partial_1f\,x\,y\cd D\,y
\end{aligned}
\]

\end{document}
